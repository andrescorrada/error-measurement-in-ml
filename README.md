error-measurement-in-ml
=======================

A monograph on how to measure the errors of machine learning algorithms when no ground truth is available.

## Why?

Data is plentiful. Machine algorithms are plentiful. Is it possible to exploit the combination of both to carry out an "error correcting" algorithm on the output of recognizers, labelers, rankers, recommenders, etc.? Or devise algorithms that can measure the error in situations where you don't have any ground truth to verify what the correct answer is?

## How?

